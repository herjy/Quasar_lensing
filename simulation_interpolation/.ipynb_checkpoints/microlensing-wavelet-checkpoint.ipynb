{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_functions import index, simulation_, plot\n",
    "from interpolation_functions import T_K\n",
    "from make_noise_updated import simulate_noise\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from microlensing import make_microlensing\n",
    "from wavelet import wavelet, iuwt\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calling the microlensing function to get magnitudes of different microlensing curves, visualized below\n",
    "mic0, mic1, mic2, mic3 = make_microlensing(u0=1.5), make_microlensing(u0=1.4, d= -1500, te= 50),make_microlensing(u0=1.9, d = 500, te = 700),make_microlensing(u0=1.1, d = 1000)\n",
    "mag0, mag1,mag2,mag3 = mic0[1], mic1[1],mic2[1],mic3[1]\n",
    "# microlensing magnitude array\n",
    "mic_mag = np.concatenate([mag0[np.newaxis,:], mag1[np.newaxis,:],mag2[np.newaxis,:],mag3[np.newaxis,:]])\n",
    "\n",
    "\n",
    "sim = simulate_noise(15) # first argument dt_max: time delay is chosen randomly between 0 and dtmax, with noise\n",
    "time_delays = sim[2]\n",
    "ts = sim[0]+np.max(time_delays) # observation time sample (same for all curves= non_shifted)+max (time delay)\n",
    "\n",
    "fs = sim[1] # f(ts)\n",
    "# f(ts) + microlensing:\n",
    "fsm = np.concatenate([(fs[0]+mag0)[np.newaxis,:],(fs[1]+mag1)[np.newaxis,:],(fs[2]+mag2)[np.newaxis,:],(fs[3]+mag3)[np.newaxis,:]])\n",
    "\n",
    "# original curve : concatenated and shifted\n",
    "f = sim[6]\n",
    "t = sim[7]\n",
    "\n",
    "sampling = 3\n",
    "h=sampling\n",
    "# desired sampling for each curve\n",
    "\n",
    "\n",
    "tk = np.linspace(np.min(ts),np.max(ts),np.int(np.abs((np.min(ts)-np.max(ts))/h)),dtype=float,retstep=True)[0]  # [1] gives approx : h\n",
    "\n",
    "\n",
    "# dt is part of the argument ts+dt -tk of the sinc matrix\n",
    "dt = np.array([1.,1.,1.,1.])\n",
    "arg = np.argsort(time_delays)[::-1] # in index terms: from highest time delay to lowest\n",
    "dt[arg[0]] = 0 #curve with highest time delay has dt = 0\n",
    "#in what comes: curve with ith highest time delay has :dt = max time delay- ith highest time delay\n",
    "dt[arg[1]] = np.max(time_delays)-time_delays[arg[1]]\n",
    "dt[arg[2]] = np.max(time_delays)-time_delays[arg[2]]\n",
    "dt[arg[3]] = np.max(time_delays)-time_delays[arg[3]]\n",
    "\n",
    "matrix = []\n",
    "for i in range(4):\n",
    "    matrix.append(np.array([(ts[:,np.newaxis])-dt[i]-tk[np.newaxis,:]])) \n",
    "matrix = np.array(matrix)\n",
    "\n",
    "A = np.sinc(np.concatenate([matrix[0],matrix[1],matrix[2],matrix[3]],axis =0)/h) # 4 x s x K  , without h* \n",
    "\n",
    "Y= np.concatenate([fsm[0][np.newaxis,:],fsm[1][np.newaxis,:],fsm[2][np.newaxis,:],fsm[3][np.newaxis,:]]) # 4 x s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplication functions:\n",
    "noise_std = sim[3]\n",
    "def AT(X,A,Y, M): \n",
    "    '''\n",
    "    calculateS the weighted mean of A.T(Y-AX)\n",
    "    input:\n",
    "    X : array with shape k, solution of interpolation\n",
    "    A : tensor of shape 4xsxk, sinc matrix\n",
    "    Y : matrix of shape 4xs, magnitudes of original time sampling\n",
    "    '''\n",
    "    \n",
    "    #M = np.zeros((4, len(tk)))\n",
    "    #M[0],M[1],M[2],M[3] = M0,M1,M2,M3\n",
    "    sum_ = 0\n",
    "    for i in range(4):\n",
    "        sum_ += np.dot(A[i].T, Y[i] - A[i] @ X - A[i] @ M[i])#*((1/noise_std[i])**2)\n",
    "    \n",
    "    return sum_#/np.sum(1/(noise_std**2))\n",
    "\n",
    "def multiplication(X,S): # X.S\n",
    "    '''\n",
    "    multiplies X by S[i] and takes the arithmetic mean\n",
    "    '''\n",
    "    this =[]\n",
    "    for i in range(4):\n",
    "        this.append(np.dot(X,S[i]))\n",
    "    this = np.array(this)\n",
    "    return np.mean(this,axis=0)\n",
    "\n",
    "def multiplication_T(X,S): # X.S.T\n",
    "\n",
    "    '''\n",
    "    multiplies X by S[i].T and take the arithmetic mean\n",
    "    '''\n",
    "    this =[]\n",
    "    for i in range(4):\n",
    "        this.append(np.dot(X,S[i].T))\n",
    "    this = np.array(this)\n",
    "    return np.mean(this,axis=0)\n",
    "\n",
    "def residuals(Y,A,X,M):\n",
    "    '''\n",
    "    calculates the residual or each while loop iteration\n",
    "    '''\n",
    "    sum = 0\n",
    "    for i in range(4):\n",
    "        sum += ((Y-A@X-A@M[i])**2)\n",
    "    return np.sum(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def linorm(S, nit):\n",
    "    '''\n",
    "    calculates the lipschitz constant given a matrix\n",
    "    '''\n",
    "    x0 = np.random.rand(S.shape[1])  # chose [1] per the implementation of the power iteration method in wiki\n",
    "    x0 = x0 /np.linalg.norm(x0)\n",
    "    for i in range(nit):\n",
    "        x = multiplication(x0,S)#np.dot(x0,S)\n",
    "        xn = np.linalg.norm(x)\n",
    "        xp = x / xn#     \n",
    "        y = multiplication_T(xp,S) # the S.T is done within the functionas S[i].T not S.T[i]\n",
    "        yn = np.linalg.norm(y)  \n",
    "        x0 = y / yn\n",
    "    return 1./xn\n",
    "mu = linorm(A,20)/170 # = 0.0038\n",
    "\n",
    "#initializing X, Ms, Count, S_var_M\n",
    "X = np.zeros(len(tk))\n",
    "M = np.zeros((4,len(tk)))\n",
    "M_new = np.zeros((4,len(tk)))\n",
    "\n",
    "\n",
    "count = 0\n",
    "R = [np.sum(Y ** 2)]\n",
    "epsilon = 0.3\n",
    "\n",
    "S_var_M = np.zeros((4,len(tk)-1)) # to store the variance in M for each M curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_ = []\n",
    "# for i in range(4):\n",
    "#     max_.append(np.max((fs[i][1:]-fs[i][:-1])))#/((ts-dt[i])[1:]-(ts-dt[i])[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = 4\n",
    "\n",
    "th_s = np.zeros(lvl) # threshold scale\n",
    "th = np.zeros(lvl)  # actual threshold for each level\n",
    "dirac = scipy.signal.unit_impulse(len(tk), idx=np.int(len(tk)/2)) # plt.plot(tk, dirac)\n",
    "\n",
    "for i in range(lvl):\n",
    "    th_s[i] = np.sum((wavelet(dirac, lvl)[i])**2) # threshold scale calculation\n",
    "\n",
    "dirac  = signal.unit_impulse(len(tk), idx = np.int(len(tk)/2) )\n",
    "thresholds = []\n",
    "for i in range(4):\n",
    "    for j in range(lvl):\n",
    "        th[j] = 5*noise_std[i]*th_s[j] # threshold calculation\n",
    "    thresholds.append(th)\n",
    "        \n",
    "thresholds = np.array(thresholds)*0.03 # shape is 4 x lvl , thresholds[i][j] is the threshold for curve i, level j\n",
    "\n",
    "def _bayes_thresh(details,var):\n",
    "    '''\n",
    "    alternate method to calculate the threshold, called the Bayes Shrink method\n",
    "    \n",
    "    input:\n",
    "    details: output of the wavelet for a specific level, ie  : w[j] for level j\n",
    "    var: std**2\n",
    "    \n",
    "    output:\n",
    "    a threshold for each level.\n",
    "    '''\n",
    "    dvar = np.mean(details*details)\n",
    "    eps = np.finfo(details.dtype).eps\n",
    "    thresh = var / np.sqrt(max(dvar - var, eps))\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e11cdcf0bb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#positivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mM_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_var = np.abs(np.max((f[1:]-f[:-1])))#/(t[1:]-t[:-1]))) # exact if without noise (f doesnt have noise)\n",
    "\n",
    "\n",
    "while (R[-1] > epsilon) and (\n",
    "        count < 5000):  # 5000 is a good amount of counts\n",
    "    X_new = X + mu * AT(X,A,Y,M)\n",
    "    X = X_new.copy()  \n",
    "    \n",
    "\n",
    "    S_var = (X[:-1]-X[1:])#/((tk[:-1]-tk[1:]))\n",
    "    sign = np.sign(S_var[np.abs(S_var) >2*max_var])\n",
    "    loc = np.where(np.abs(S_var) >2*max_var)\n",
    "    X[loc] = X[loc] - 2*max_var*sign\n",
    "        \n",
    "    X[X<0] = 0 #positivity\n",
    "\n",
    "    for i in range(4):\n",
    "        M_new[i] = M[i] + mu*np.dot(A[i].T, Y[i] - A[i] @ X- A[i] @ M[i])\n",
    "        M[i] = M_new[i].copy()  \n",
    "        \n",
    "        S_var_M[i] = ((M[i])[:-1]-(M[i])[1:])#/((tk[:-1]-tk[1:]))\n",
    "        sign = np.sign(S_var_M[i][np.abs(S_var_M[i]) >2*max_var])\n",
    "        loc = np.where(np.abs(S_var_M[i]) >2*max_var)\n",
    "        M[i][loc] = M[i][loc] - 2*max_var*sign\n",
    "               \n",
    "        w = wavelet(M[i], lvl)\n",
    "        for j in range(lvl-1): # lvl-1 to not include the last level\n",
    "#             threshold = _bayes_thresh(w[j],noise_std[i]**2)     # to use the bayes Shrink, uncomment\n",
    "#             (w[j])[w[j] <= threshold] = 0 \n",
    "            (w[j])[w[j] <= (thresholds[i][j])] = 0 \n",
    "            \n",
    "        #w[lvl-1] = np.zeros(len(tk)) # set last level coeff to 0\n",
    "        M[i] = iuwt(w)  # inverse wavelet\n",
    "        \n",
    "        M[i][M[i]<0] = 0 # positivity\n",
    "\n",
    "    R.append(residuals(Y,A,X,M)) \n",
    "    count += 1\n",
    "\n",
    "\n",
    "plt.title('Convergence')\n",
    "plt.plot(np.array(R[1:]))\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cut = np.logical_and(X < np.max(Y), X > np.min(Y))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "## with microlensing:\n",
    "# for i in range(4):\n",
    "#     plt.plot(ts-dt[i], Y[i], 'o', label='microlensed light curve '+str(i))    \n",
    "\n",
    "\n",
    "# without microlensing:\n",
    "for i in range(4):\n",
    "    plt.plot(ts-dt[i], fs[i], 'o', label='intrinsic light curve '+str(i), color = 'blue')    \n",
    "\n",
    "# resulting interpoation, apply [cut] to X if desired\n",
    "plt.plot(tk, X,'o', label='interpolated intrinsic light curve', color='black')   \n",
    "plt.plot(tk, M[0],'o', label='interpolated microlensing0',color = 'r')\n",
    "plt.plot(tk, M[1],'o', label='interpolated microlensing1', color = 'g')\n",
    "plt.plot(tk, M[2],'o', label='interpolated microlensing2', color = 'pink')\n",
    "plt.plot(tk, M[3],'o', label='interpolated microlensing3', color = 'purple')\n",
    "\n",
    "# microlensing original curves\n",
    "plt.plot(mic0[0],mic_mag[0],'o', label = \"microlensing curve 0\", color = 'r',markersize=12)\n",
    "plt.plot(mic0[0],mic_mag[1],'o', label = \"microlensing curve 0\", color = 'g',markersize=12)\n",
    "plt.plot(mic0[0],mic_mag[2],'o', label = \"microlensing curve 0\", color = 'pink',markersize=12)\n",
    "plt.plot(mic0[0],mic_mag[3],'o', label = \"microlensing curve 0\", color = 'purple',markersize=12)\n",
    "\n",
    "\n",
    "#plt.plot(tk, X,'o', label='interpolated', color='black')\n",
    "#plt.plot(t,f,'o', label = 'true')\n",
    "plt.xlabel('time[days]')\n",
    "plt.ylabel('magnitude')\n",
    "#plt.title('demixing signals: level 4, bolded are original microlensing curves, all except purple are zero')\n",
    "plt.legend()\n",
    "#plt.savefig(\"wavelet level 4 using \\\"BayesShrink\\\" threshold method .png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
